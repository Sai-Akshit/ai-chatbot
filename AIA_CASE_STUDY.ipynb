{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sai-Akshit/ai-chatbot/blob/main/AIA_CASE_STUDY.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPyLmKojGGwP"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install gradio\n",
        "!pip install huggingface_hub\n",
        "!pip install langchain-community langchain-core"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJfjEJbwGmbI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gradio as gr\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain import LLMChain, PromptTemplate\n",
        "from langchain.memory import ConversationBufferMemory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fci9byLAGrW6"
      },
      "outputs": [],
      "source": [
        "OPENAI_API_KEY=\"OPENAI_API_KEY\"\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7AnNKzZG2FO"
      },
      "outputs": [],
      "source": [
        "template = \"\"\"You are a helpful assistant to answer user queries.\n",
        "{chat_history}\n",
        "User: {user_message}\n",
        "Chatbot:\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"chat_history\", \"user_message\"], template=template\n",
        ")\n",
        "\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdEV6hMJG4xt"
      },
      "outputs": [],
      "source": [
        "llm_chain = LLMChain(\n",
        "    llm=ChatOpenAI(temperature='0.5', model_name=\"gpt-3.5-turbo\"),\n",
        "    prompt=prompt,\n",
        "    verbose=True,\n",
        "    memory=memory,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wl77cfyIG85T"
      },
      "outputs": [],
      "source": [
        "def get_text_response(user_message,history):\n",
        "    response = llm_chain.predict(user_message = user_message)\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0JxyOMt_HAr-"
      },
      "outputs": [],
      "source": [
        "demo = gr.ChatInterface(get_text_response, examples=[\"How are you doing?\",\"What are your interests?\",\"Which places do you like to visit?\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sWVT_2_KHE2G"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    demo.launch(debug=True) #To create a public link, set `share=True` in `launch()`. To enable errors and logs, set `debug=True` in `launch()`."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}